{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "REzjr490GdJA"
      },
      "source": [
        "Prepare Main project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_google_colab = False\n",
        "first_run = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfCbuSXiFVei",
        "outputId": "1c58e0ba-e540-459d-da89-e7b3b1478dea"
      },
      "outputs": [],
      "source": [
        "# Clone main project\n",
        "if(use_google_colab and first_run):\n",
        "    print(\"clone main project\")\n",
        "    !git clone \"https://github.com/albirrkarim/post-processing-segment-anything-model.git\"\n",
        "    !cd /content/post-processing-segment-anything-model && mv * \"../\"\n",
        "    !rm -rf \"post-processing-segment-anything-model\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XkEV-sypGVs8"
      },
      "source": [
        "Prepare Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66mAgmAFHcg",
        "outputId": "54a66cb0-a166-40ea-abd5-5ee325b9a5a7"
      },
      "outputs": [],
      "source": [
        "# Clone all algorithm sam, matteformer, aim, inspyrenet\n",
        "\n",
        "if(use_google_colab and first_run):\n",
        "    print(\"clone all algorithm sam, matteformer, aim, inspyrenet\")\n",
        "\n",
        "    # !mkdir \"algorithms\"\n",
        "\n",
        "    # !cd \"algorithms\" && git clone https://github.com/webtoon/matteformer.git\n",
        "\n",
        "    !cd \"algorithms\" && git clone https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "    # !cd \"algorithms\" && git clone https://github.com/JizhiziLi/AIM.git\n",
        "\n",
        "    !pip install transparent-background\n",
        "\n",
        "    !pip install \"algorithms/segment-anything\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KfOq5sA5GiL3"
      },
      "source": [
        "Prepare Models (.pth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "if(use_google_colab):\n",
        "    MODEL_DIR = \"models/\"\n",
        "    AIM_NET_MODEL_PATH = MODEL_DIR+\"aimnet_pretrained_matting.pth\"\n",
        "    RESNET_MODEL_PATH = MODEL_DIR+\"r34mp_pretrained_imagenet.pth.tar\"\n",
        "    MATTEFORMER_MODEL_PATH = MODEL_DIR+\"matteformer.pth\"\n",
        "    INSPYRENET_MODEL_PATH = MODEL_DIR+\"InSPyReNet_SwinB_DIS5K.pth\"\n",
        "else:\n",
        "    MODEL_DIR = \"/Users/susanto/Documents/Proyek/best-remove-background/models/\"\n",
        "    AIM_NET_MODEL_PATH = MODEL_DIR+\"aimnet_pretrained_matting.pth\"\n",
        "    RESNET_MODEL_PATH = MODEL_DIR+\"r34mp_pretrained_imagenet.pth.tar\"\n",
        "    MATTEFORMER_MODEL_PATH = MODEL_DIR+\"matteformer_image_matting.pth\"\n",
        "    INSPYRENET_MODEL_PATH = MODEL_DIR+\"InSPyReNet_SwinB_Large.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "QW8dDpXdFHcj",
        "outputId": "c731c697-684b-49bc-8260-999df10ce5e0"
      },
      "outputs": [],
      "source": [
        "# download all models .pth\n",
        "import gdown\n",
        "\n",
        "if (use_google_colab and first_run):\n",
        "    print(\"Download all models\")\n",
        "    !mkdir \"models\"\n",
        "    # AIM NET\n",
        "    # aimnet_pretrained_matting.pth\n",
        "    gdown.download(\n",
        "        \"https://drive.google.com/uc?export=download&id=16dd1FGMcsMTqR6EfD2T9mtRmPwxnY0zs\",\n",
        "        output=AIM_NET_MODEL_PATH)\n",
        "\n",
        "    # r34mp_pretrained_imagenet.pth.tar\n",
        "    gdown.download(\"https://drive.google.com/uc?export=download&id=18Pt-klsbkiyonMdGi6dytExQEjzBnHwY\",\n",
        "                   output=RESNET_MODEL_PATH)\n",
        "\n",
        "    # Matteformer\n",
        "    gdown.download(\"https://drive.google.com/u/0/uc?id=1AU7uM1dtYjEhtOa_9OGfoQUE-tmW9mX5&export=download\",\n",
        "                   output=MATTEFORMER_MODEL_PATH)\n",
        "\n",
        "    # Inspyrenet\n",
        "    gdown.download(\"https://drive.google.com/u/0/uc?id=1aCxHMbhvj8ah77jXVgqvqImQA_Y0G-Yg&export=download\",\n",
        "                   output=INSPYRENET_MODEL_PATH)\n",
        "\n",
        "    first_run = False\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import all make model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wGBLW54NFHck"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "sys.path.append('driver')\n",
        "sys.path.append('algorithms/AIM/core')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AIM\n",
        "from aim import makeAIMNetModel, inference_img as AIMNET_Predictor\n",
        "from aim import calculate_sad_mse_mad_whole_img,compute_connectivity_loss_whole_image,compute_gradient_whole_image\n",
        "\n",
        "aim_model = makeAIMNetModel(device=DEVICE,model_path=AIM_NET_MODEL_PATH,res_net_model_path=RESNET_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B /Users/susanto/Documents/Proyek/best-remove-background/models/InSPyReNet_SwinB_Large.pth\n",
            "Settings -> Mode=fast, Device=cpu, Torchscript=enabled\n"
          ]
        }
      ],
      "source": [
        "# Inspyrenet\n",
        "\n",
        "from transparent_background import Remover\n",
        "\n",
        "InSPyReNet_remover = Remover(\n",
        "    fast=True, jit=True, device=DEVICE, ckpt=INSPYRENET_MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matteformer\n",
        "sys.path.append('algorithms/matteformer')\n",
        "\n",
        "import networks as matteformer_networks\n",
        "import utils_matteformer as utils\n",
        "from inference import generator_tensor_dict, single_inference\n",
        "\n",
        "\n",
        "def makeMatteFormerModel(device='cpu'):\n",
        "    checkpoint_path = MATTEFORMER_MODEL_PATH\n",
        "\n",
        "    # build model\n",
        "    model = matteformer_networks.get_generator(is_train=False)\n",
        "    # model.cpu()\n",
        "\n",
        "    # load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
        "\n",
        "    model.load_state_dict(utils.remove_prefix_state_dict(\n",
        "        checkpoint['state_dict']), strict=True)\n",
        "\n",
        "    model.to(device)\n",
        "    model = model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "matteformer_model = makeMatteFormerModel(DEVICE)\n",
        "\n",
        "def ImageMattingMatteFormer(image_path, trimap_path):\n",
        "    image_dict = generator_tensor_dict(image_path, trimap_path)\n",
        "    alpha_pred = single_inference(matteformer_model, image_dict, device=DEVICE)\n",
        "\n",
        "    return alpha_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
          ]
        }
      ],
      "source": [
        "sys.path.append('helper')\n",
        "\n",
        "from helper import *\n",
        "\n",
        "from post_helper import *\n",
        "\n",
        "from sam_helper import *\n",
        "\n",
        "from evaluation_helper import *\n",
        "\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "import datetime\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rgbToAlpha2D(rgb_gray_scale):\n",
        "    # # Convert the image to grayscale\n",
        "    # gray_image = np.mean(rgb_gray_scale, axis=2)\n",
        "\n",
        "    # # Normalize the pixel values between 0 and 1\n",
        "    # normalized_image = gray_image / np.max(gray_image)\n",
        "\n",
        "    # # Scale the values to the desired range (0-255)\n",
        "    # scaled_image = (normalized_image * 255).astype(np.uint8)\n",
        "\n",
        "    # return scaled_image\n",
        "    alpha = np.array(rgb_gray_scale)\n",
        "    alpha = alpha[:, :, 0] if alpha.ndim > 2 else alpha\n",
        "\n",
        "    return alpha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getMSEandSAD(rgba_img, alpha_img):\n",
        "    # mse = getMSE(rgba_img, alpha_img)\n",
        "    # sad = getSAD(rgba_img, alpha_img)\n",
        "\n",
        "    predict = rgba_img[:, :, 3]\n",
        "\n",
        "    predict = predict / 255\n",
        "    alpha_img = alpha_img / 255\n",
        "\n",
        "    sad, mse, mad = calculate_sad_mse_mad_whole_img(predict, alpha_img)\n",
        "    conn = compute_connectivity_loss_whole_image(predict, alpha_img)\n",
        "    grad = compute_gradient_whole_image(predict, alpha_img)\n",
        "\n",
        "    return {\n",
        "        \"sad\": sad,\n",
        "        \"mse\": mse,\n",
        "        \"mad\": mad,\n",
        "        \"conn\": conn,\n",
        "        \"grad\": grad\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_image_with_bounding_box(img, bounding_box):\n",
        "    x1, y1, x2, y2 = bounding_box\n",
        "    cropped_image = img[y1:y2, x1:x2,]\n",
        "    return cropped_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getImage(name, folder):\n",
        "    return np.asarray(Image.open(\"datasets/AIM-500/\"+folder+\"/\"+name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cropUnusedBlankPixelExtended(myImage):\n",
        "    # https://stackoverflow.com/a/53829086\n",
        "    if isinstance(myImage, Image.Image):\n",
        "        PIL_image = myImage\n",
        "    else:\n",
        "        PIL_image = Image.fromarray(myImage.astype('uint8'), 'RGBA')\n",
        "\n",
        "    bounding = PIL_image.getbbox()\n",
        "\n",
        "    bounding = extendBoundaries(np.asarray(myImage), bounding, 50)\n",
        "\n",
        "    if (bounding != None):\n",
        "        PIL_image = PIL_image.crop(bounding)\n",
        "    else:\n",
        "        width, height = PIL_image.size\n",
        "        bounding = (0, 0, width, height)\n",
        "\n",
        "    return [PIL_image, np.array(bounding).astype(int)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def addTheRestMask(masks):\n",
        "    mask = masks[0]['segmentation']\n",
        "\n",
        "    for i in range(0, len(masks)):\n",
        "        # Apply Segment Mask\n",
        "        segmentation = masks[i]['segmentation']\n",
        "        mask = np.logical_or(mask, segmentation)\n",
        "\n",
        "    inverted_mask = mask ^ True\n",
        "\n",
        "    masks.append({\n",
        "        \"segmentation\": inverted_mask\n",
        "    })\n",
        "\n",
        "    return masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findSamObjectMaskThatMatchDataset(file_name, masks, threshold=0.5):\n",
        "    # if the iou between sam and the original is < 0.5\n",
        "    # it mean sam detect false object from the original object in dataset.\n",
        "    # then don't do post processing because the dataset AIM-500 is focused on one object in the picture\n",
        "\n",
        "    file_name_origin = os.path.splitext(file_name)[0]\n",
        "    maximal = 0\n",
        "    maximal_index = 0\n",
        "\n",
        "    # Evaluate ori vs SAM\n",
        "    origin_img = getImage(file_name_origin+\".png\", \"mask\")\n",
        "    origin_mask = origin_img[:, :,\n",
        "                             0] > 0 if origin_img.ndim > 2 else origin_img > 0\n",
        "\n",
        "    for index in range(0, len(masks)):\n",
        "        sam_mask = masks[index][\"segmentation\"]\n",
        "\n",
        "        # Evaluate SAM before post processing\n",
        "        iou = getIoU(origin_mask, sam_mask)\n",
        "\n",
        "        if (iou > maximal):\n",
        "            maximal = iou\n",
        "            maximal_index = index\n",
        "\n",
        "    # add more mask if the iou is increased\n",
        "    basic_mask = masks[maximal_index][\"segmentation\"]\n",
        "    current_iou = maximal\n",
        "\n",
        "    for index in range(0, len(masks)):\n",
        "        sam_mask = masks[index][\"segmentation\"]\n",
        "\n",
        "        result = np.logical_or(sam_mask, basic_mask)\n",
        "\n",
        "        # Evaluate SAM before post processing\n",
        "        iou = getIoU(origin_mask, result)\n",
        "\n",
        "        if (iou > current_iou):\n",
        "            current_iou = iou\n",
        "            basic_mask = result\n",
        "\n",
        "    return basic_mask\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Processing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "CACHE=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def useCache(IDX_IMG, pipeline_name, value=None):\n",
        "    if (not CACHE):\n",
        "        return None\n",
        "\n",
        "    cache_path = \"precompute/\"+IDX_IMG+\"_\"+pipeline_name+\".pickle\"\n",
        "    if (value == None):\n",
        "        if (os.path.exists(cache_path)):\n",
        "            # Open the pickle file\n",
        "            with open(cache_path, \"rb\") as file:\n",
        "                loaded_dict = pickle.load(file)\n",
        "            return loaded_dict\n",
        "        return None\n",
        "    else:\n",
        "        # save cache\n",
        "        # Save the dictionary to the generated filename\n",
        "        with open(cache_path, \"wb\") as file:\n",
        "            pickle.dump(value, file)\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def AIM_Pipeline(IDX_IMG, PIL_image, dilated_sam_mask, croped, blank_image, bounding, origin_alpha, origin_mask):\n",
        "    cache = useCache(IDX_IMG, \"aim\")\n",
        "\n",
        "    if (cache == None):\n",
        "        start_time = time.time()\n",
        "\n",
        "        predict = AIMNET_Predictor(aim_model,np.asarray(PIL_image),device=DEVICE)\n",
        "\n",
        "        predict = (predict * 255).astype(np.uint8)\n",
        "\n",
        "        predict[dilated_sam_mask == False] = 0\n",
        "\n",
        "        applied_alpha_aim = croped.copy()\n",
        "        applied_alpha_aim[:, :, 3] = predict\n",
        "\n",
        "        # back to original size\n",
        "        a = blank_image.copy()\n",
        "        alpha_aim_original_size = patchToBoundingBox(\n",
        "            a, bounding, applied_alpha_aim)\n",
        "\n",
        "        Image.fromarray(alpha_aim_original_size).save(\n",
        "            IDX_IMG+\"_aim.png\")\n",
        "\n",
        "        # Evaluate SAM before post processing\n",
        "        AIM_result_origin_size_mask = alpha_aim_original_size[:, :, 3] > 0\n",
        "\n",
        "        res = getMSEandSAD(alpha_aim_original_size, origin_alpha)\n",
        "        res[\"iou\"] = getIoU(origin_mask, AIM_result_origin_size_mask)\n",
        "        res[\"time\"] = time.time() - start_time\n",
        "\n",
        "        useCache(IDX_IMG, \"aim\", [predict, res])\n",
        "    else:\n",
        "        predict, res = cache\n",
        "\n",
        "    return predict, res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Matteformer_Pipeline(IDX_IMG, name_before, JPG_PATH, croped, blank_image, bounding, origin_alpha, origin_mask):\n",
        "    cache = useCache(IDX_IMG, \"matteformer_\"+name_before)\n",
        "\n",
        "    if (cache == None):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Image Matting: MatteFormer\n",
        "        alpha_pred = ImageMattingMatteFormer(JPG_PATH, IDX_IMG+\"_trimap_\"+name_before+\".jpg\")\n",
        "\n",
        "        croped_a = croped.copy()\n",
        "        croped_a[:, :, 3] = alpha_pred\n",
        "\n",
        "        # Back to original size\n",
        "        a = blank_image.copy()\n",
        "        croped_a = patchToBoundingBox(a, bounding, croped_a)\n",
        "\n",
        "        Image.fromarray(croped_a).save(\n",
        "            IDX_IMG+\"_\"+name_before+\"_matteformer.png\")\n",
        "\n",
        "        MatteFormer_result_mask = croped_a[:, :, 3] > 0\n",
        "\n",
        "        res = getMSEandSAD(croped_a, origin_alpha)\n",
        "        res[\"iou\"] = getIoU(origin_mask, MatteFormer_result_mask)\n",
        "        res[\"time\"] = time.time() - start_time\n",
        "\n",
        "        useCache(IDX_IMG, \"matteformer_\"+name_before, res)\n",
        "    else:\n",
        "        res = cache\n",
        "\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def InSpyReNet_Pipeline(IDX_IMG, JPG_PATH, dilated_sam_mask, blank_image, bounding, origin_alpha, origin_mask):\n",
        "    cache = useCache(IDX_IMG, \"InSpyReNet\")\n",
        "\n",
        "    if (cache == None):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        PIL_image = Image.open(JPG_PATH)\n",
        "        InSpyReNet_result = InSPyReNet_remover.process(PIL_image)\n",
        "\n",
        "        # Remove all region  outside dilated mask\n",
        "        InSpyReNet_result[dilated_sam_mask == False] = [0, 0, 0, 0]\n",
        "\n",
        "        # Back to original size\n",
        "        a = blank_image.copy()\n",
        "        InSpyReNet_result_origin_size = patchToBoundingBox(\n",
        "            a, bounding, InSpyReNet_result)\n",
        "\n",
        "        Image.fromarray(InSpyReNet_result_origin_size).save(\n",
        "            IDX_IMG+\"_InSpy.png\")\n",
        "\n",
        "        InSpyReNet_result_origin_size_mask = InSpyReNet_result_origin_size[:, :, 3] > 0\n",
        "\n",
        "        res = getMSEandSAD(InSpyReNet_result_origin_size, origin_alpha)\n",
        "        res[\"iou\"] = getIoU(\n",
        "            origin_mask, InSpyReNet_result_origin_size_mask)\n",
        "\n",
        "        res[\"time\"] = time.time() - start_time\n",
        "\n",
        "        useCache(IDX_IMG, \"InSpyReNet\", [InSpyReNet_result, res])\n",
        "    else:\n",
        "        InSpyReNet_result, res = cache\n",
        "\n",
        "    return InSpyReNet_result, res\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testPostProcessing(file_name, sam_mask):\n",
        "\n",
        "    # Extract the base name without the extension\n",
        "    file_name_origin = os.path.splitext(file_name)[0]\n",
        "\n",
        "    image_path = 'datasets/AIM-500/original/'+file_name_origin+\".jpg\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # RGB numpy array to RGBA numpy array\n",
        "    rgba_image = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)\n",
        "    rgba_image[:, :, :3] = image\n",
        "    rgba_image[:, :, 3] = 255\n",
        "\n",
        "    blank_image = np.zeros(\n",
        "        (rgba_image.shape[0], rgba_image.shape[1], 4), dtype=np.uint8)\n",
        "\n",
        "    OUTPUT_FOLDER = \"output/\"\n",
        "\n",
        "    index = file_name_origin\n",
        "\n",
        "    evaluation = {\n",
        "        \"sam\": 0,\n",
        "\n",
        "        \"InSpyReNet\": 0,\n",
        "        \"InSpyReNet_MatteFormer\": 0,\n",
        "\n",
        "        \"AIM\": 0,\n",
        "        \"AIM_MatteFormer\": 0,\n",
        "    }\n",
        "\n",
        "    # sam_mask = masks[index][\"segmentation\"]\n",
        "\n",
        "    IDX_IMG = OUTPUT_FOLDER+str(index)\n",
        "\n",
        "    applied_mask = rgba_image.copy()\n",
        "    applied_mask[sam_mask == False] = [0, 0, 0, 0]\n",
        "\n",
        "    # Crop aplied transparent region (aplied mask)\n",
        "    [PIL_image, bounding] = cropUnusedBlankPixelExtended(\n",
        "        Image.fromarray(applied_mask))\n",
        "\n",
        "    # Crop original image\n",
        "    croped = crop_image_with_bounding_box(rgba_image.copy(), bounding)\n",
        "\n",
        "    # Evaluate ori vs SAM\n",
        "    origin_img = getImage(file_name_origin+\".png\", \"mask\")\n",
        "    origin_alpha = rgbToAlpha2D(origin_img)\n",
        "    origin_mask = origin_img[:, :,\n",
        "                             0] > 0 if origin_img.ndim > 2 else origin_img > 0\n",
        "\n",
        "    # Save origin image\n",
        "    origin_dataset = rgba_image.copy()\n",
        "    origin_dataset[:, :, 3] = origin_alpha\n",
        "\n",
        "    # Evaluate SAM before post processing\n",
        "    res = getMSEandSAD(applied_mask, origin_alpha)\n",
        "    res[\"iou\"] = getIoU(origin_mask, sam_mask)\n",
        "    evaluation[\"sam\"] = res\n",
        "\n",
        "    Image.fromarray(origin_dataset).save(IDX_IMG+\"_origin_dataset.png\")\n",
        "    PIL_image = Image.fromarray(applied_mask)\n",
        "    PIL_image.save(IDX_IMG+\"_origin_sam_applied.png\")\n",
        "    # PIL_image.save(IDX_IMG+\"_origin_mask.png\")\n",
        "\n",
        "    # Save original mask\n",
        "    saveMask(sam_mask, IDX_IMG+\"_sam.jpg\")\n",
        "\n",
        "    # Croped original image to JPG for input AIM and  InSpyReNet\n",
        "    JPG_PATH = IDX_IMG+\"_origin.jpg\"\n",
        "    PIL_image = Image.fromarray(croped)\n",
        "    PIL_image = PIL_image.convert(\"RGB\")\n",
        "    PIL_image.save(JPG_PATH)\n",
        "\n",
        "    # POST PROCESSING PIPELINE\n",
        "    # Remove all region  outside dilated mask\n",
        "    cropped_mask = cropToBoundingBox(sam_mask, bounding)\n",
        "    dilated_sam_mask = binary_dilation(cropped_mask)\n",
        "\n",
        "    # AIM NET _________________________________________\n",
        "    predict, res = AIM_Pipeline(\n",
        "        IDX_IMG, PIL_image, dilated_sam_mask, croped, blank_image, bounding, origin_alpha, origin_mask)\n",
        "\n",
        "    evaluation[\"AIM\"] = res\n",
        "\n",
        "    if (not os.path.exists(IDX_IMG+\"_trimap_aim.jpg\")):\n",
        "        trimap = np.zeros_like(predict)\n",
        "        trimap[predict == 0] = 0  # Background\n",
        "        trimap[predict == 255] = 255  # Foreground\n",
        "        trimap[(predict > 0) & (predict < 255)] = 128  # Unknown region\n",
        "\n",
        "        Image.fromarray(trimap).save(IDX_IMG+\"_trimap_aim.jpg\")\n",
        "\n",
        "    res = Matteformer_Pipeline(\n",
        "        IDX_IMG, \"aim\", JPG_PATH, croped, blank_image, bounding, origin_alpha, origin_mask)\n",
        "\n",
        "    evaluation[\"AIM_MatteFormer\"] = res\n",
        "\n",
        "    # Dichotomous Image Segmentation ______________________\n",
        "\n",
        "    # InSpyReNet\n",
        "    InSpyReNet_result, res = InSpyReNet_Pipeline(\n",
        "        IDX_IMG, JPG_PATH, dilated_sam_mask, blank_image, bounding, origin_alpha, origin_mask)\n",
        "\n",
        "    evaluation[\"InSpyReNet\"] = res\n",
        "\n",
        "    # Image Matting Process _______________________________\n",
        "\n",
        "    # Trimap\n",
        "    if (not os.path.exists(IDX_IMG+\"_trimap_InSpyReNet.jpg\")):\n",
        "        trimap = makeTrimap(InSpyReNet_result)\n",
        "        Image.fromarray(trimap).save(IDX_IMG+\"_trimap_InSpyReNet.jpg\")\n",
        "\n",
        "    res = Matteformer_Pipeline(\n",
        "        IDX_IMG, \"InSpyReNet\", JPG_PATH, croped, blank_image, bounding, origin_alpha, origin_mask)\n",
        "    evaluation[\"InSpyReNet_MatteFormer\"] = res\n",
        "\n",
        "    return evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def formatEvaluation(arrEval):\n",
        "    for i in range(0, len(arrEval)):\n",
        "        print(\"Eval \", i)\n",
        "        for key, value in arrEval[i].items():\n",
        "            print(key, end=\" | \")\n",
        "\n",
        "            # Check if variable is an integer\n",
        "            if isinstance(value, int):\n",
        "                print(\"No value\")\n",
        "            else:\n",
        "                for ev, v in value.items():\n",
        "                    formatted_number = \"{:.3f}\".format(v)\n",
        "                    print(ev + ':', formatted_number, end=\" | \")\n",
        "\n",
        "            print(\"\\n\")\n",
        "\n",
        "        print(\"\\n\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def saveEvalResult(my_dict):\n",
        "    # Get the current date, hour, and minute\n",
        "    current_time = datetime.datetime.now()\n",
        "    formatted_time = current_time.strftime(\"%Y-%m-%d_%H-%M\")\n",
        "\n",
        "    # Generate the filename with date, hour, and minute\n",
        "    filename = f\"eval_result_{formatted_time}.pickle\"\n",
        "\n",
        "    # Save the dictionary to the generated filename\n",
        "    with open(\"evaluations/\"+filename, \"wb\") as file:\n",
        "        pickle.dump(my_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def openEvalResult(file_name):\n",
        "    # Open the pickle file\n",
        "    with open(file_name, \"rb\") as file:\n",
        "        loaded_dict = pickle.load(file)\n",
        "\n",
        "    return loaded_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def printEvaluation(sum_dict):\n",
        "    for key, value in sum_dict.items():\n",
        "        if isinstance(value, int):\n",
        "            print(\"Evaluation from \", value, \" data\")\n",
        "        else:\n",
        "            print(key, end=\" | \")\n",
        "            for ky, val in value.items():\n",
        "                formatted_number = \"{:.3f}\".format(sum_dict[key][ky])\n",
        "                print(ky + ':', formatted_number, end=\" | \")\n",
        "\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def formatEvaluationMean(arrEval):\n",
        "    length = len(arrEval)\n",
        "    # Get all key\n",
        "    sum_dict = {\n",
        "        \"length\": length\n",
        "    }\n",
        "\n",
        "    for i in range(0, 1):\n",
        "        for key, value in arrEval[i].items():\n",
        "            sum_dict[key] = {\n",
        "                \"sad\": 0,\n",
        "                \"mse\": 0,\n",
        "                \"mad\": 0,\n",
        "                \"conn\": 0,\n",
        "                \"grad\": 0,\n",
        "                \"iou\": 0,\n",
        "                \"time\": 0\n",
        "            }\n",
        "\n",
        "    # print(sum_dict)\n",
        "\n",
        "    for i in range(0, len(arrEval)):\n",
        "        for key, value in arrEval[i].items():\n",
        "            # Check if variable is an integer\n",
        "            if not isinstance(value, int):\n",
        "                for ev, v in value.items():\n",
        "                    sum_dict[key][ev] = sum_dict[key][ev]+v\n",
        "\n",
        "    # print(sum_dict)\n",
        "    for key, value in sum_dict.items():\n",
        "        if not isinstance(value, int):\n",
        "            for ky, val in value.items():\n",
        "                sum_dict[key][ky] = sum_dict[key][ky]/length\n",
        "\n",
        "    # print(sum_dict)\n",
        "    # print(\"Evaluation from \", length, \" data\")\n",
        "\n",
        "    # PRINT\n",
        "    printEvaluation(sum_dict)\n",
        "\n",
        "    # saveEvalResult(sum_dict)\n",
        "    return sum_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "arrEval = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "ORIGINAL_PATH = \"precompute/sam_mask\"\n",
        "img_list = os.listdir(ORIGINAL_PATH)\n",
        "# print(img_list)\n",
        "\n",
        "for i in range(0, 1):\n",
        "    file_name = img_list[i]\n",
        "    file_name_origin = os.path.splitext(file_name)[0]\n",
        "\n",
        "    # if (os.path.exists(\"output/\"+file_name_origin+\"_origin_dataset.png\") == False):\n",
        "    PIL_image = Image.open(ORIGINAL_PATH+\"/\"+file_name)\n",
        "\n",
        "    mask_np = np.asarray(PIL_image)\n",
        "\n",
        "    mask = mask_np > 0\n",
        "\n",
        "    res = testPostProcessing(file_name, mask)\n",
        "\n",
        "    arrEval.append(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval  0\n",
            "sam | sad: 75.281 | mse: 0.030 | mad: 0.036 | conn: 76.616 | grad: 142.766 | iou: 0.895 | \n",
            "\n",
            "InSpyReNet | sad: 41.405 | mse: 0.009 | mad: 0.020 | conn: 39.199 | grad: 48.499 | iou: 0.911 | time: 5.595 | \n",
            "\n",
            "InSpyReNet_MatteFormer | sad: 15.046 | mse: 0.002 | mad: 0.007 | conn: 13.022 | grad: 13.441 | iou: 0.932 | time: 15.984 | \n",
            "\n",
            "AIM | sad: 27.457 | mse: 0.006 | mad: 0.013 | conn: 25.108 | grad: 45.445 | iou: 0.912 | time: 10.725 | \n",
            "\n",
            "AIM_MatteFormer | sad: 21.640 | mse: 0.005 | mad: 0.010 | conn: 19.211 | grad: 33.486 | iou: 0.912 | time: 16.219 | \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "formatEvaluation(arrEval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation from  1  data\n",
            "\n",
            "\n",
            "sam | sad: 75.281 | mse: 0.030 | mad: 0.036 | conn: 76.616 | grad: 142.766 | iou: 0.895 | time: 0.000 | \n",
            "\n",
            "InSpyReNet | sad: 41.405 | mse: 0.009 | mad: 0.020 | conn: 39.199 | grad: 48.499 | iou: 0.911 | time: 5.595 | \n",
            "\n",
            "InSpyReNet_MatteFormer | sad: 15.046 | mse: 0.002 | mad: 0.007 | conn: 13.022 | grad: 13.441 | iou: 0.932 | time: 15.984 | \n",
            "\n",
            "AIM | sad: 27.457 | mse: 0.006 | mad: 0.013 | conn: 25.108 | grad: 45.445 | iou: 0.912 | time: 10.725 | \n",
            "\n",
            "AIM_MatteFormer | sad: 21.640 | mse: 0.005 | mad: 0.010 | conn: 19.211 | grad: 33.486 | iou: 0.912 | time: 16.219 | \n",
            "\n"
          ]
        }
      ],
      "source": [
        "sum_dict = formatEvaluationMean(arrEval)\n",
        "\n",
        "# saveEvalResult(sum_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "coba_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
